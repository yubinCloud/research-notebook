---
title: 🐋 引入 NLI 模型来为 RAG 去噪
permalink: /arxiv/2310.01558/
author: Bin Yu
createTime: 2024/05/15 17:11:00
---

> 论文：[Making Retrieval-Augmented Language Models Robust to Irrelevant Context](https://openreview.net/forum?id=ZS4m74kZpH)
>
> ⭐⭐⭐
>
> ICLR 2024, arXiv:2310.01558
>
> Code: [github.com/oriyor/ret-robust](https://github.com/oriyor/ret-robust)

## 论文速读

这篇论文引入 NLI（Natural Language Inference）模型来判定 retrieved doc 是否需要用于辅助 LLM 回答。

NLI 模型用于判定一个 hypothesis 与 premise 的关系如下三者之一："蕴含（entailed）"、"中立（neutral）"、"矛盾（contradicted）"。**具体到 RAG 中，question + LLM answer 作为 premise，retrieved doc 作为 hypothesis，由 NLI 模型判定两者是否是 entailed**：

- 是的话，就辅助 LLM 再次生成 answer 作为最终答案
- 不是的话，就使用标准的 LLM，防止无关上下文来分散 LLM 的注意力

> 该论文的工作，NLI 模型使用的是 BART-large

**这其实这篇论文的假设是有问题的，以底座模型的答案作为基准来衡量检索信息是否是噪声，那其实把 RAG 通过检索召回额外信息增加 LLM 本身缺乏的知识的这部分的能力也损失了。这种假设在底座本身就能回答的问题上额外增加了相关召回信息，可能会让底座的答案更加详细精准。但是底座本身不能回答或者回答错误的部分，那基于底座的答案去做噪声判断会让让模型错上加错**。

此外，该论文工作还尝试训练一个健壮的用于 RAG 的 LLM。因为作者认为，原生的 LLM 由于其没有在 retrieved passages 上做训练，所以它对噪音上下文很脆弱是可以预料的。为此，作者特意收集一批带有噪音文档的数据来对 LLM 做 SFT，数据的收集其实就是将检索到的 top-1 和排名较低的文档共同作为 retrieved context。**这种做法其实就是在训练样本中强行引入噪声，让模型学习识别噪声的能力，当引入噪声信息时能够基于底座本身具有的知识正确作答**。

## 实验结果

通过实验发现，论文提出的采用 NLI 来识别无关文档的方法，由于其假设有点问题，导致其底座模型在本身信息缺失的情况西，做降低 RAG 的性能，因为它把与底座答案不一致的正确信息都过滤了。

另外，使用含有噪音检索上下文的数据来对底座模型做 SFT 之后，即便加入不相关的召回信息都可以让 RAG 模型变好，这说明引入噪声做 SFT 的方式可以有助于帮助 RAG 模型在一定程度上去除噪声带来的影响。

## 反思

- **在实际业务落地上可以借鉴引入随机噪声的思想，在 sft 阶段不仅只加入最相关的召回结果，同时以一定的比例加入随机召回信息作为噪声**，可以提升模型识别噪声的能力，在线上推理阶段，如果 top 的召回信息是不相关的错误信息，模型有一定的识别能力。
- 我们其实可以在 RAG 的过程中增加判断召回文档是否相关，以及结合相关文档给出正确答案这样的 cot 任务，这样输出的内容不会过长，不会带来额外的线上推理耗时，同时也能一定程度上缓解 RAG 检索信息存在噪声的问题。

