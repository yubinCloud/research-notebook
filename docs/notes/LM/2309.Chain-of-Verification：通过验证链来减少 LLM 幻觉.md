---
title: 🐋 Chain-of-Verification：通过验证链来减少 LLM 幻觉
permalink: /paper/chain-of-verification/
author: Bin Yu
createTime: 2024/05/10 19:56:00
---

> 论文：[Chain-of-Verification Reduces Hallucination in Large Language Models](http://arxiv.org/abs/2309.11495)
>
> ⭐⭐⭐
>
> arXiv:2309.11495

## 论文速读

LLM 由于不可避免地会产生幻觉，现有的研究主要鼓励 LLM 在产生 response 之前生成内部思想的推理链，或者通过 self-critique 等技术来更新它们的初始 response。

本工作提出了 <mark>Chain-of-Verification</mark>（CoVe）的方法，示例如下：

![image-20240510200249963](https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20240510200249963.png)

CoVe 主要执行四个核心步骤：

1. *Generate Baseline Response*：给定一个 query，使用 LLM 生成一个 response
2. *Plan Verifications*：基于原始的 query 和上一轮得到的原始 response，让 LLM 生成一个 verification question 列表，并用于帮助 LLM 进行自我分析
3. *Execute Verifications*：依次回答每个 verification question，从而对照原始 response 检查是否存在不一致或错误
4. *Generate Final Verified Response*：考虑前面步骤的结果，完成最终的修正后的 response

每一个步骤的执行都是通过 prompt 相同的 LLM 来实现的。其中 1、2、4 步骤使用了一个 single prompt 实现，3 步骤则复杂了一些，尝试了多种实现方式，具体可参考论文。

## 总结

验证链（CoVe）通过让 LLM 审议自身的 response 来自我纠正从而减少 LLM 的幻觉问题，特别是将验证过程分解为一组更加简单的问题，能够让模型相比于回答原始查询时能有更高的准确性，从而能够发现一些自身原始 response 可能存在的问题。

论文也指出，在第三个步骤“执行验证”中，使用 RAG 方法可能会进一步带来收益。
