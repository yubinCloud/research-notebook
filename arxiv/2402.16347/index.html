<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.9" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.55" /><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;if (um === 'dark' || (um !== 'light' && sm)) {document.documentElement.classList.add('dark');}})();</script><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><title>🌙 CodeS：Text2SQL 领域的开源语言模型</title><meta name="description" content=""><link rel="preload" href="/research-notebook/assets/style-Cec0e0LW.css" as="style"><link rel="stylesheet" href="/research-notebook/assets/style-Cec0e0LW.css"><link rel="modulepreload" href="/research-notebook/assets/app-s5JIphqh.js"><link rel="modulepreload" href="/research-notebook/assets/index.html-B0q2VZS4.js"><link rel="prefetch" href="/research-notebook/assets/index.html-B-j-ryWq.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D4spU_9v.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-B0-1BBu1.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-SLLIY8d9.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C65jmr_M.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C-bL2yAS.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C7B5e00U.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Nt9kYeWR.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CE_bMlSy.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CLhUsc3g.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DXgEbOI-.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-v1oOswjF.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CBJ8xjXF.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D4Fq4d_T.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-ByB-z2iB.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Q9nU2u_y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D8yUAJ7Y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Dtno56yj.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BDK4L6jX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Dc5x4woP.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-eGfCPn-9.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D70LzGEm.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BPemUoR7.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BwgVpDih.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DlaBYZPe.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CgVNpCXw.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-G5FDBLuS.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-uDKSTe9v.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BVMJJZGD.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CrHd4gIE.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BiSS2sK0.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DXcBEjAg.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CQoGuxuN.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CRi0y6sX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BKNM53Nr.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C0kRXJHb.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-QyJX4BVb.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CJvsDrCW.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BwT074si.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-sp3GJ4_Y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C3rZacVL.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CYDgqNcV.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CDChQk7d.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C9fq1LXw.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-_hma_Fnn.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-7G48gGCA.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BlT-qKyg.js" as="script"><link rel="prefetch" href="/research-notebook/assets/404.html-V2miJEAG.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BcMo9zlU.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CrhXs5dX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DEOpBtft.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BKeLltu8.js" as="script"><link rel="prefetch" href="/research-notebook/assets/SearchBox-CGeHVkxs.js" as="script"></head><body><div id="app"><!--[--><div class="theme-plume" data-v-ba475dda><!--[--><!--[--><span tabindex="-1" data-v-4bbc90d0></span><a href="#LayoutContent" class="skip-link visually-hidden" data-v-4bbc90d0> Skip to content </a><!--]--><!----><div class="nav-wrapper" data-v-ba475dda data-v-7a402866><div class="navbar-wrapper" data-v-7a402866 data-v-c0f362fa><div class="container" data-v-c0f362fa><div class="title" data-v-c0f362fa><div class="navbar-title" data-v-c0f362fa data-v-b77839f9><a class="auto-link link title" href="/" data-v-b77839f9 data-v-5111f611><!--[--><!----> <!--]--><!----></a></div></div><div class="content" data-v-c0f362fa><div class="curtain" data-v-c0f362fa></div><div class="content-body" data-v-c0f362fa><div class="navbar-search search" data-v-c0f362fa><div class="search-wrapper" data-v-60fa285e><!----><div id="local-search" data-v-60fa285e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-60fa285e><span class="mini-search-button-container"><svg class="mini-search-search-icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="navbar-menu menu" data-v-c0f362fa data-v-b0c203ca><span id="main-nav-aria-label" class="visually-hidden" data-v-b0c203ca>Main Navigation</span><!--[--><!--[--><a class="auto-link link navbar-menu-link" href="/category/LM/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>LLM</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/LLM-evaluation/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>LLM 评估</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/RAG/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>RAG</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/Text2SQL/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>Text2SQL</i><!--]--><!----></a><!--]--><!--]--></nav><!----><div class="navbar-appearance appearance" data-v-c0f362fa data-v-376ec936><button class="switch-wrapper switch-appearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-376ec936 data-v-b27b6603 data-v-f90faf21><span class="check" data-v-f90faf21><span class="icon" data-v-f90faf21><!--[--><span class="vpi-sun sun" data-v-b27b6603></span><span class="vpi-moon moon" data-v-b27b6603></span><!--]--></span></span></button></div><!----><div class="flyout-wrapper navbar-extra extra" data-v-c0f362fa data-v-7914c0f6 data-v-7e56bc7a><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-7e56bc7a><span class="vpi-more-horizontal icon" data-v-7e56bc7a></span></button><div class="menu" data-v-7e56bc7a><div class="menu-wrapper" data-v-7e56bc7a data-v-b4fba565><!----><!--[--><!--[--><!----><div class="group" data-v-7914c0f6><div class="item appearance" data-v-7914c0f6><p class="label" data-v-7914c0f6>外观</p><div class="appearance-action" data-v-7914c0f6><button class="switch-wrapper switch-appearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-7914c0f6 data-v-b27b6603 data-v-f90faf21><span class="check" data-v-f90faf21><span class="icon" data-v-f90faf21><!--[--><span class="vpi-sun sun" data-v-b27b6603></span><span class="vpi-moon moon" data-v-b27b6603></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><button type="button" class="navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-c0f362fa data-v-7e5802de><span class="container" data-v-7e5802de><span class="top" data-v-7e5802de></span><span class="middle" data-v-7e5802de></span><span class="bottom" data-v-7e5802de></span></span></button></div></div></div></div><!----></div><!----><!----><div id="LayoutContent" class="layout-content" data-v-ba475dda data-v-094016f3><!--[--><div class="has-aside plume-page" data-v-5b0e3d8f><div class="container" data-v-5b0e3d8f><div class="aside" data-v-5b0e3d8f><div class="aside-container" data-v-5b0e3d8f><div class="aside-content" data-v-5b0e3d8f><div class="page-aside" data-v-5b0e3d8f data-v-f8c78049><div class="has-outline page-aside-outline" data-v-f8c78049><div class="content" data-v-f8c78049><div class="outline-marker" data-v-f8c78049></div><div class="outline-title" data-v-f8c78049><span data-v-f8c78049>此页内容</span><span class="vpi-print icon" data-v-f8c78049></span></div><nav aria-labelledby="doc-outline-aria-label" data-v-f8c78049><span id="doc-outline-aria-label" class="visually-hidden" data-v-f8c78049> Table of Contents for current page </span><ul class="root" data-v-f8c78049 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#一、论文速读" data-v-9a83b7a1>一、论文速读</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#二、增量预训练-incremental-pre-training" data-v-9a83b7a1>二、增量预训练（Incremental pre-training）</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#三、database-prompt-construction" data-v-9a83b7a1>三、Database prompt construction</a><ul class="nested" data-v-9a83b7a1 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#_3-1-schema-filter" data-v-9a83b7a1>3.1 Schema Filter</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_3-2-value-retriever" data-v-9a83b7a1>3.2 Value Retriever</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_3-3-db-metadata" data-v-9a83b7a1>3.3 DB metadata</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_3-4-prompt-构建" data-v-9a83b7a1>3.4 prompt 构建</a><!----></li><!--]--></ul></li><li data-v-9a83b7a1><a class="outline-link" href="#四、new-domain-adaption" data-v-9a83b7a1>四、New Domain Adaption</a><ul class="nested" data-v-9a83b7a1 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#_4-1-question-sql-增强" data-v-9a83b7a1>4.1 Question -&gt; SQL 增强</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_4-2-sql-question-增强" data-v-9a83b7a1>4.2 SQL -&gt; Question 增强</a><!----></li><!--]--></ul></li><li data-v-9a83b7a1><a class="outline-link" href="#五、codes-的使用" data-v-9a83b7a1>五、CodeS 的使用</a><ul class="nested" data-v-9a83b7a1 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#_5-1-监督微调" data-v-9a83b7a1>5.1 监督微调</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_5-2-few-shot-icl" data-v-9a83b7a1>5.2 Few-shot ICL</a><!----></li><!--]--></ul></li><li data-v-9a83b7a1><a class="outline-link" href="#六、实验" data-v-9a83b7a1>六、实验</a><ul class="nested" data-v-9a83b7a1 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#_6-1-延迟和部署要求" data-v-9a83b7a1>6.1 延迟和部署要求</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_6-2-其他的实验" data-v-9a83b7a1>6.2 其他的实验</a><!----></li><!--]--></ul></li><li data-v-9a83b7a1><a class="outline-link" href="#七、总结" data-v-9a83b7a1>七、总结</a><!----></li><!--]--></ul></nav></div></div></div></div></div></div><div class="content" data-v-5b0e3d8f><div class="content-container" data-v-5b0e3d8f><!--[--><!----><h1 class="page-title" data-v-dbc950ba>🌙 CodeS：Text2SQL 领域的开源语言模型</h1><div class="page-meta-wrapper" data-v-dbc950ba><p class="author" data-v-dbc950ba><span class="icon vpi-user" data-v-dbc950ba></span><span data-v-dbc950ba>Bin Yu</span></p><p class="reading-time" data-v-dbc950ba><span class="vpi-books icon" data-v-dbc950ba></span><span data-v-dbc950ba>1957字</span><span data-v-dbc950ba>约7分钟</span></p><!----><p class="create-time" data-v-dbc950ba><span class="vpi-clock icon" data-v-dbc950ba></span><span data-v-dbc950ba>2024-06-12</span></p></div><!--]--><!--[--><div style="position:relative;" data-v-5b0e3d8f><div class="plume-content" data-v-5b0e3d8f><blockquote><p>论文：<a href="https://dl.acm.org/doi/10.1145/3654930" target="_blank" rel="noopener noreferrer">CodeS: Towards Building Open-source Language Models for Text-to-SQL<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p><p>⭐⭐⭐⭐</p><p>arXiv:2402.16347, SIGMOD 2024</p><p>人大</p><p>Code: <a href="https://github.com/RUCKBReasoning/codes" target="_blank" rel="noopener noreferrer">CodeS | GitHub<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p></blockquote><h2 id="一、论文速读" tabindex="-1"><a class="header-anchor" href="#一、论文速读"><span>一、论文速读</span></a></h2><p>本文提出一个开源的专门用于 Text2SQL 任务的 LLM —— <mark>CodeS</mark>，有多个参数规模的版本（1B ~ 15B），它是基于 <strong>StarCdoer</strong> 基座模型，使用 Text2SQL 相关的数据集继续训练得到的。同时，论文提出了在训练这个模型和使用这个模型一些方法。</p><p>论文提出的一些 challenges 和解决方案：</p><ul><li><strong>C1：如何让小模型具备复杂的 Text2SQL 推理能力</strong>？由于现有的 PLM（如 LLaMA-2）的训练数据中，与 SQL 相关的内容只占预料的很小一部分，这种数据偏差可能会阻碍模型的 SQL 生成能力。因此，本文提出一种<strong>增量预训练方法</strong>，利用与 Text2SQL 任务相关的数据集来训练。</li><li><strong>C2：如何生成一个好的 prompt 来解决 Schema Link 的困难</strong>？本文提出了一系列过滤方法，筛选出只与问题有关的 schema 输送给 LLM。</li><li><strong>C3：如何让 LLM 自适应地迁移到新 domain 的 DB 中</strong>？这个问题的主要障碍在于缺乏用于微调的 pairs，因此本文提出了一种<strong>双向数据增强技术</strong>，在少量人工操作下生成足够的微调数据集。</li></ul><p>总的来说，为了解决这三个问题，论文一共引入了三个组件来分别解决：Incremental pre-training（下图 a）、Database prompt construction（下图 b）、New Domain Adaption（下图 c）：</p><!----><p>另外，上图的 (d) 和 (e) 展示 CodeS 模型的使用方式。</p><h2 id="二、增量预训练-incremental-pre-training" tabindex="-1"><a class="header-anchor" href="#二、增量预训练-incremental-pre-training"><span>二、增量预训练（Incremental pre-training）</span></a></h2><p>从 3 个维度来收集用于训练的数据：</p><ul><li><strong>SQL 相关数据</strong>：使用了 StarCoder 的与训练语料库种的 SQL 片段</li><li><strong>NL 相关数据</strong>：从多个来源收集了 4.5GB 的高质量对话数据</li><li><strong>NL2Code 数据</strong>：主要包含如下四类数据： <ul><li>CoNaLa、StaQC 包含需要 NL2Python 和 NL2SQL 的 pairs</li><li>CodeAlpaca 包含许多与代码相关的指令遵顼数据</li><li>Jupyter-structured-clean-dedup 是 StarCoder 的预训练语料库的子集</li><li>NL-SQL-458K 是本文精心制作的一个数据集，包含大量的 NL-SQL pairs</li></ul></li></ul><p>使用上面数据，对 StarCoder 进行增量预训练：对 SQL 相关数据做 2 个 epoch 的训练，对 NL 相关和 NL2Code 相关数据做 1 个 epoch 的训练。</p><p>训练的思路就是给定一个 sequence，让 LLM 能够最大化整个 sequence 的 likelihood，这可以通过计算每个 token 的条件概率的乘积来实现：</p><!----><h2 id="三、database-prompt-construction" tabindex="-1"><a class="header-anchor" href="#三、database-prompt-construction"><span>三、Database prompt construction</span></a></h2><p>高质量的 prompt 能够为 LM 提供有价值的见解，从而提高 LLM 的表现。为了构造一个好的 prompt，这里主要采用了两个关键策略：schema filter 和 value retriever。</p><h3 id="_3-1-schema-filter" tabindex="-1"><a class="header-anchor" href="#_3-1-schema-filter"><span>3.1 Schema Filter</span></a></h3><p>由于 LLM 的 context window 装不下整个 DB 的 schema 信息，因此有必要过滤出有用的 schema。<mark>Schema Filter</mark> 的作用就是为一个 question 筛选出最相关的 tables 和 columns。</p><p>筛选的方法是：计算每个 column 与 question 的相关性分数，然后基于这些分数来选出 Top-K1 的 tables，然后对这些 tables 的每一个选出其中 Top-K2 的 columns。</p><h3 id="_3-2-value-retriever" tabindex="-1"><a class="header-anchor" href="#_3-2-value-retriever"><span>3.2 Value Retriever</span></a></h3><p>Value retriver 用于从 DB 中检索出与 question 相关的 cell values 并用于执行 schema linking。</p><p>这里使用了”由粗到细“的匹配方法：先使用 BM25 索引来快速粗粒度的初始搜索，然后使用 LCS 进行细粒度匹配。这种方式极大减少了 LCS 调用次数，提高了检索速度。</p><h3 id="_3-3-db-metadata" tabindex="-1"><a class="header-anchor" href="#_3-3-db-metadata"><span>3.3 DB metadata</span></a></h3><p>DB 有 4 类 metadata 也对于构建 prompt 很有用：</p><ol><li>Column Data Types：列的数据类型限制了它允许的操作</li><li>Comments：能够有效解决一些 column 的命名会让人产生歧义的问题</li><li>Representative DB values：每一列中选出一些有代表的 cell values 是很有用的</li><li>Primary and Foreign Keys：在实践中，使用唯一标识符来表示主键，为每个外键表示为 <code>{T1}.{COL1} = {T2}.{COL2}</code> 的形式来构建 prompt</li></ol><h3 id="_3-4-prompt-构建" tabindex="-1"><a class="header-anchor" href="#_3-4-prompt-构建"><span>3.4 prompt 构建</span></a></h3><p>有了上面的方案，我们可以得到如下用于构建 prompt 的信息：</p><!----><p>有了这些信息，就可以构建出一个 prompt 来让 LLM 根据 question 生成 SQL 了。</p><h2 id="四、new-domain-adaption" tabindex="-1"><a class="header-anchor" href="#四、new-domain-adaption"><span>四、New Domain Adaption</span></a></h2><p>现实场景下，我们会面临各种 domain 的数据库，为了做适应性微调，这里提出了一个<strong>双向数据增强技术</strong>，以较小的注释成本来自动生成大量可靠且通用的 question-SQL pairs。</p><h3 id="_4-1-question-sql-增强" tabindex="-1"><a class="header-anchor" href="#_4-1-question-sql-增强"><span>4.1 Question -&gt; SQL 增强</span></a></h3><p>这部分 augmentation 是寻找与人类偏好一致的 question-sql pairs。具体来说，就是先从用户那里收集一些真实的、有代表性的 NL question，然后再手动注释对应的 SQL，从而获得一些高质量的 pairs。</p><p>上面得到的 pairs 还是不足以微调的。进一步引入了一个 two-stage 的 prompting 方法：</p><ul><li>先 prompt GPT3.5 来生成潜在的问题，然后从真实问题中吸取灵感、有效捕捉用户意图</li><li>再让 GPT3.5 为这些问题合成对应的 SQL 查询</li></ul><h3 id="_4-2-sql-question-增强" tabindex="-1"><a class="header-anchor" href="#_4-2-sql-question-增强"><span>4.2 SQL -&gt; Question 增强</span></a></h3><p>使用一组通用 template 来生成通用的 pairs，这里使用的是 Spider 的常见 SQL template，比如 <code>返回 {TABLE} 的最低 {COLUMN}</code>，以及对应的 SQL template <code>SELECT {COLUMN} FROM {TABLE} GROUP BY {COLUMN} ORDER BY COUNT(*) ASC LIMIT 1</code>。</p><p>这些生成的 question 可能看起来有点死板，因此可以使用 GPT3.5 对它们进行重新表述。</p><h2 id="五、codes-的使用" tabindex="-1"><a class="header-anchor" href="#五、codes-的使用"><span>五、CodeS 的使用</span></a></h2><p>有两种使用方式：监督微调 or few-shot ICL。</p><h3 id="_5-1-监督微调" tabindex="-1"><a class="header-anchor" href="#_5-1-监督微调"><span>5.1 监督微调</span></a></h3><p>使用我们在 New Domain Adaption 得到的 domain-specific 数据，利用 DB prompt + question 就可以对 CodeS 做 SFT 了。</p><p>微调之后，就可以使用这个 LLM 输入 DB prompt + NL 来输出 SQL 了。</p><h3 id="_5-2-few-shot-icl" tabindex="-1"><a class="header-anchor" href="#_5-2-few-shot-icl"><span>5.2 Few-shot ICL</span></a></h3><p>为了让 ICL 效果更好，这里使用一个 retriever 从 dataset 中检索出有价值的 K 个 demonstrations 来做 ICL。</p><p><strong>最基本的方法是，根据 question 的 semantic similarity 来做检索，但这会有一个问题：检索时会过于重视 question 中的 entities</strong>。但我们的想法是，demonstrations 应该更偏向翻译问题的 pattern。比如对于问题 ”1949 年出生的歌手中谁唱了最多的歌曲“，retriever 可能会检索出很多关于歌手或者歌曲的数据。</p><p>为了避免过度强调 entities，这里掩盖掉 question 中的 entities，使其专注于 question 的核心结构。</p><p>具体来说，这里使用 NLTK 工具来删除 question 中识别到的实体，并使用 SimCSE 来评估句子相似度。称这里提出的检索方法为 <mark>question-pattern-aware demonstration retriever</mark>。</p><h2 id="六、实验" tabindex="-1"><a class="header-anchor" href="#六、实验"><span>六、实验</span></a></h2><h3 id="_6-1-延迟和部署要求" tabindex="-1"><a class="header-anchor" href="#_6-1-延迟和部署要求"><span>6.1 延迟和部署要求</span></a></h3><p>CodeS 可以进行私有化部署，之前的 DIN-SQL + GPT4 在 Spider 数据集上平均每个 sample 花费 60s，但是本文的 1B、3B、7B 和 15B 的版本的 inference 时间分别为 0.6s、0.9s、1.1s 和 1.5s。</p><p>另外，CodeS 还很适合实际部署，当以 Float16 精度操作时，这些变体分别需要 10G、13G、20G 和 35G 的 GPU 内存容量。</p><p>这样，我们就可以在本地机器上部署 CodeS，而不需要昂贵的 GPT-4 API。</p><h3 id="_6-2-其他的实验" tabindex="-1"><a class="header-anchor" href="#_6-2-其他的实验"><span>6.2 其他的实验</span></a></h3><p>具体参考原论文。包括微调的评估、ICL 的评估和消融实验。</p><h2 id="七、总结" tabindex="-1"><a class="header-anchor" href="#七、总结"><span>七、总结</span></a></h2><p>这篇论文开源了一个很不错的 Text2SQL 领域的 LLM，并同时开放了相关的新的数据集，在实际部署时，无论是基于 CodeS 还是另外再微调，这篇论文的思路都值得参考。</p></div><!----></div><footer class="page-footer" data-v-5b0e3d8f data-v-bb1af879><!----><div class="contributors" data-v-bb1af879><span class="contributors-label" data-v-bb1af879>贡献者: </span><span class="contributors-info" data-v-bb1af879><!--[--><!--[--><span class="contributor" title="email: yubin_SkyWalker@yeah.net" data-v-bb1af879>yubinCloud</span><!----><!--]--><!--]--></span></div><!----></footer><!----><!--]--></div></div></div></div><button style="display:none;" type="button" class="back-to-top-button" aria-label="back to top" data-v-ba475dda data-v-b42999a2><span class="percent" data-v-b42999a2>0%</span><span class="show icon vpi-back-to-top" data-v-b42999a2></span><svg aria-hidden="true" data-v-b42999a2><circle cx="50%" cy="50%" style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-b42999a2></circle></svg></button><footer class="plume-footer" data-v-ba475dda data-v-46d530a6><div class="container" data-v-46d530a6><p class="message" data-v-46d530a6>Power by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://github.com/pengzhanbo/vuepress-theme-plume">vuepress-theme-plume</a></p><!----></div></footer><!--]--></div><!--]--></div><!--[--><!--]--><!--]--></div><script type="module" src="/research-notebook/assets/app-s5JIphqh.js" defer></script></body></html>