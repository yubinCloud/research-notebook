<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.9" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.55" /><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;if (um === 'dark' || (um !== 'light' && sm)) {document.documentElement.classList.add('dark');}})();</script><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><title>🐋 UPR：使用 LLM 来做检索后的 re-rank</title><meta name="description" content=""><link rel="preload" href="/research-notebook/assets/style-Cec0e0LW.css" as="style"><link rel="stylesheet" href="/research-notebook/assets/style-Cec0e0LW.css"><link rel="modulepreload" href="/research-notebook/assets/app-s5JIphqh.js"><link rel="modulepreload" href="/research-notebook/assets/index.html-CBJ8xjXF.js"><link rel="prefetch" href="/research-notebook/assets/index.html-B-j-ryWq.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D4spU_9v.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-B0-1BBu1.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-SLLIY8d9.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C65jmr_M.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C-bL2yAS.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C7B5e00U.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Nt9kYeWR.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CE_bMlSy.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CLhUsc3g.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DXgEbOI-.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-v1oOswjF.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D4Fq4d_T.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-ByB-z2iB.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Q9nU2u_y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D8yUAJ7Y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Dtno56yj.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BDK4L6jX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-Dc5x4woP.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-eGfCPn-9.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-D70LzGEm.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BPemUoR7.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BwgVpDih.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DlaBYZPe.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CgVNpCXw.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-G5FDBLuS.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-uDKSTe9v.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BVMJJZGD.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CrHd4gIE.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BiSS2sK0.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DXcBEjAg.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CQoGuxuN.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CRi0y6sX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BKNM53Nr.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C0kRXJHb.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-QyJX4BVb.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CJvsDrCW.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BwT074si.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-sp3GJ4_Y.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C3rZacVL.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-B0q2VZS4.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CYDgqNcV.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CDChQk7d.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-C9fq1LXw.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-_hma_Fnn.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-7G48gGCA.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BlT-qKyg.js" as="script"><link rel="prefetch" href="/research-notebook/assets/404.html-V2miJEAG.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BcMo9zlU.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-CrhXs5dX.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-DEOpBtft.js" as="script"><link rel="prefetch" href="/research-notebook/assets/index.html-BKeLltu8.js" as="script"><link rel="prefetch" href="/research-notebook/assets/SearchBox-CGeHVkxs.js" as="script"></head><body><div id="app"><!--[--><div class="theme-plume" data-v-ba475dda><!--[--><!--[--><span tabindex="-1" data-v-4bbc90d0></span><a href="#LayoutContent" class="skip-link visually-hidden" data-v-4bbc90d0> Skip to content </a><!--]--><!----><div class="nav-wrapper" data-v-ba475dda data-v-7a402866><div class="navbar-wrapper" data-v-7a402866 data-v-c0f362fa><div class="container" data-v-c0f362fa><div class="title" data-v-c0f362fa><div class="navbar-title" data-v-c0f362fa data-v-b77839f9><a class="auto-link link title" href="/" data-v-b77839f9 data-v-5111f611><!--[--><!----> <!--]--><!----></a></div></div><div class="content" data-v-c0f362fa><div class="curtain" data-v-c0f362fa></div><div class="content-body" data-v-c0f362fa><div class="navbar-search search" data-v-c0f362fa><div class="search-wrapper" data-v-60fa285e><!----><div id="local-search" data-v-60fa285e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-60fa285e><span class="mini-search-button-container"><svg class="mini-search-search-icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="navbar-menu menu" data-v-c0f362fa data-v-b0c203ca><span id="main-nav-aria-label" class="visually-hidden" data-v-b0c203ca>Main Navigation</span><!--[--><!--[--><a class="auto-link link navbar-menu-link" href="/category/LM/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>LLM</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/LLM-evaluation/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>LLM 评估</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/RAG/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>RAG</i><!--]--><!----></a><!--]--><!--[--><a class="auto-link link navbar-menu-link" href="/category/Text2SQL/" data-v-b0c203ca data-v-c7242555 data-v-5111f611><!--[--><!----><i data-v-c7242555>Text2SQL</i><!--]--><!----></a><!--]--><!--]--></nav><!----><div class="navbar-appearance appearance" data-v-c0f362fa data-v-376ec936><button class="switch-wrapper switch-appearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-376ec936 data-v-b27b6603 data-v-f90faf21><span class="check" data-v-f90faf21><span class="icon" data-v-f90faf21><!--[--><span class="vpi-sun sun" data-v-b27b6603></span><span class="vpi-moon moon" data-v-b27b6603></span><!--]--></span></span></button></div><!----><div class="flyout-wrapper navbar-extra extra" data-v-c0f362fa data-v-7914c0f6 data-v-7e56bc7a><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-7e56bc7a><span class="vpi-more-horizontal icon" data-v-7e56bc7a></span></button><div class="menu" data-v-7e56bc7a><div class="menu-wrapper" data-v-7e56bc7a data-v-b4fba565><!----><!--[--><!--[--><!----><div class="group" data-v-7914c0f6><div class="item appearance" data-v-7914c0f6><p class="label" data-v-7914c0f6>外观</p><div class="appearance-action" data-v-7914c0f6><button class="switch-wrapper switch-appearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-7914c0f6 data-v-b27b6603 data-v-f90faf21><span class="check" data-v-f90faf21><span class="icon" data-v-f90faf21><!--[--><span class="vpi-sun sun" data-v-b27b6603></span><span class="vpi-moon moon" data-v-b27b6603></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><button type="button" class="navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-c0f362fa data-v-7e5802de><span class="container" data-v-7e5802de><span class="top" data-v-7e5802de></span><span class="middle" data-v-7e5802de></span><span class="bottom" data-v-7e5802de></span></span></button></div></div></div></div><!----></div><!----><!----><div id="LayoutContent" class="layout-content" data-v-ba475dda data-v-094016f3><!--[--><div class="has-aside plume-page" data-v-5b0e3d8f><div class="container" data-v-5b0e3d8f><div class="aside" data-v-5b0e3d8f><div class="aside-container" data-v-5b0e3d8f><div class="aside-content" data-v-5b0e3d8f><div class="page-aside" data-v-5b0e3d8f data-v-f8c78049><div class="has-outline page-aside-outline" data-v-f8c78049><div class="content" data-v-f8c78049><div class="outline-marker" data-v-f8c78049></div><div class="outline-title" data-v-f8c78049><span data-v-f8c78049>此页内容</span><span class="vpi-print icon" data-v-f8c78049></span></div><nav aria-labelledby="doc-outline-aria-label" data-v-f8c78049><span id="doc-outline-aria-label" class="visually-hidden" data-v-f8c78049> Table of Contents for current page </span><ul class="root" data-v-f8c78049 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#一、upr-论文速读" data-v-9a83b7a1>一、UPR 论文速读</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#二、开源-llm-本身就是强-zero-shot-的-qlm-re-ranker" data-v-9a83b7a1>二、开源 LLM 本身就是强 zero-shot 的 QLM re-ranker</a><ul class="nested" data-v-9a83b7a1 data-v-9a83b7a1><!--[--><li data-v-9a83b7a1><a class="outline-link" href="#_2-1-多种-qlm-re-ranker" data-v-9a83b7a1>2.1 多种 QLM re-ranker</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_2-2-实验" data-v-9a83b7a1>2.2 实验</a><!----></li><li data-v-9a83b7a1><a class="outline-link" href="#_2-3-一个有效的-ranking-pipeline" data-v-9a83b7a1>2.3 一个有效的 ranking pipeline</a><!----></li><!--]--></ul></li><li data-v-9a83b7a1><a class="outline-link" href="#总结" data-v-9a83b7a1>总结</a><!----></li><!--]--></ul></nav></div></div></div></div></div></div><div class="content" data-v-5b0e3d8f><div class="content-container" data-v-5b0e3d8f><!--[--><!----><h1 class="page-title" data-v-dbc950ba>🐋 UPR：使用 LLM 来做检索后的 re-rank</h1><div class="page-meta-wrapper" data-v-dbc950ba><p class="author" data-v-dbc950ba><span class="icon vpi-user" data-v-dbc950ba></span><span data-v-dbc950ba>Bin Yu</span></p><p class="reading-time" data-v-dbc950ba><span class="vpi-books icon" data-v-dbc950ba></span><span data-v-dbc950ba>1295字</span><span data-v-dbc950ba>约4分钟</span></p><!----><p class="create-time" data-v-dbc950ba><span class="vpi-clock icon" data-v-dbc950ba></span><span data-v-dbc950ba>2024-05-14</span></p></div><!--]--><!--[--><div style="position:relative;" data-v-5b0e3d8f><div class="plume-content" data-v-5b0e3d8f><blockquote><p>论文：<a href="https://aclanthology.org/2022.emnlp-main.249" target="_blank" rel="noopener noreferrer">Improving Passage Retrieval with Zero-Shot Question Generation<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p><p>⭐⭐⭐⭐</p><p>EMNLP 2022, arXiv:2204.07496</p><p>Code: <a href="https://github.com/DevSinghSachan/unsupervised-passage-reranking" target="_blank" rel="noopener noreferrer">github.com/DevSinghSachan/unsupervised-passage-reranking<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p></blockquote><hr><blockquote><p>论文：<a href="https://aclanthology.org/2023.findings-emnlp.590" target="_blank" rel="noopener noreferrer">Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p><p>⭐⭐⭐⭐</p><p>EMNLP 2023, arXiv:2310.13243</p><p>Code: <a href="https://github.com/ielab/llm-qlm" target="_blank" rel="noopener noreferrer">github.com/ielab/llm-qlm<span class="vpi-external-link external-icon" data-v-9f412e4e></span></a></p></blockquote><hr><h2 id="一、upr-论文速读" tabindex="-1"><a class="header-anchor" href="#一、upr-论文速读"><span>一、UPR 论文速读</span></a></h2><blockquote><p>关于 Improving Passage Retrieval with Zero-Shot Question Generation 这篇论文</p></blockquote><p>论文提出了一个基于 LLM 的 re-ranker：<mark>UPR</mark>（<em>Unsupervised Passage Re-ranker</em>），它不需要任何标注数据用于训练，只需要一个通用的 PLM（pretrained LM），并且可以用在多种类型的检索思路上。</p><p>给定一个 corpus 包含所有的 evidence documents，给定一个 question，由 Retriever 来从 corpus 中检索出 top-K passages，re-ranker 的任务就是把这 K 个 passages 做重新排序，期待重排后再交给 LLM 做 RAG 能提升效果。</p><!----><p>本论文的工作中，使用 LLM 来为每一个 passage 计算一个 <strong>relevance score</strong>，然后按照 relevance scores 来对这些 passages 做排序。passages <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的 relevance score 的计算方式是：以 passage <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 为条件，计算 LLM 生成 question <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 的 log-likelihood <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log p(q|z_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：</p><!----><blockquote><p>关于为什么使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(q|z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 来计算 relevance score 而非用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(z|q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span>，原因在于在假设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log p(z_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是都一样的话，按照 Bayes 公式来算的话，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(q|z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(z|q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span> 呈正相关的关系。此外，使用 p(q|z) 允许模型利用交叉注意力机制（cross-attention）在问题和段落之间建立联系。而且实验发现使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(q|z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 效果更好。</p><!----><p>其实从感性上想一想，也是通过 prompt 让 LLM 去计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(q|z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 来建模 question 和 passage 更合理。</p></blockquote><h2 id="二、开源-llm-本身就是强-zero-shot-的-qlm-re-ranker" tabindex="-1"><a class="header-anchor" href="#二、开源-llm-本身就是强-zero-shot-的-qlm-re-ranker"><span>二、开源 LLM 本身就是强 zero-shot 的 QLM re-ranker</span></a></h2><p><strong>QLM</strong>（<em>Query Likelihood Model</em>） 是指，通过计算特定 question 下 document 的概率来理解 docs 和 queries 的语义关系。QLM re-ranker 就是借助这个概率得出相关性分数从而做出排名，进而实现 re-rank。前面介绍的 UPR 就是一种 QLM re-ranker。</p><p>在前面介绍的 UPR 中，使用了 T0 LLM 模型作为 QLM 从而实现了有效的 re-rank，但是由于 T0 在许多 QG(Question Generation) 数据集上做了微调，所以该工作不能完全反映通用的 zero-shot 的 QLM ranking 场景。</p><p><strong>本工作研究了使用 LLaMA 和 Falcon 这两个 decoder-only 的模型作为 QLM 来做 re-rank 任务的表现</strong>，这两个 LLM 都没有在 QG 数据集上做训练。</p><h3 id="_2-1-多种-qlm-re-ranker" tabindex="-1"><a class="header-anchor" href="#_2-1-多种-qlm-re-ranker"><span>2.1 多种 QLM re-ranker</span></a></h3><p>本文工作设计了多种 QLM re-ranker，下面分别做一个介绍。</p><h4 id="_1-zero-shot-qlm-re-ranker" tabindex="-1"><a class="header-anchor" href="#_1-zero-shot-qlm-re-ranker"><span>1）Zero-shot QLM re-ranker</span></a></h4><p>类似于前面 UPR 的做法，借助于 QLM 计算出一个 relevance score，计算方法也一样（以 retrieved doc 为条件的 question 的概率）：</p><!----><h4 id="_2-bm25-插值的-re-ranker" tabindex="-1"><a class="header-anchor" href="#_2-bm25-插值的-re-ranker"><span>2）BM25 插值的 re-ranker</span></a></h4><p>除了使用 QLM 计算出来的分数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>Q</mi><mi>L</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{QLM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，还融入第一阶段的检索器 BM25 给出的相关性分数，两者通过权重共同计算最终的 relevance score：</p><!----><h4 id="_3-few-shot-qlm-re-ranker" tabindex="-1"><a class="header-anchor" href="#_3-few-shot-qlm-re-ranker"><span>3）Few-shot QLM re-ranker</span></a></h4><p>在前面 zero-shot 的基础上，使用 LLM 时，设计一个 prompt template 并加入一些 few-shot exemplars。</p><h3 id="_2-2-实验" tabindex="-1"><a class="header-anchor" href="#_2-2-实验"><span>2.2 实验</span></a></h3><p>论文详细介绍了多个实验，感兴趣可以参考原论文，这里列出几个结论：</p><ul><li>在 QG 数据集（NS NARCO 数据集）上微调的 retriever 和 re-ranker 在所有数据集上表现都由于 zero-shot 的 retriever 和 QLM re-ranker，这是意料之中的，因为这些方法会受益于大量人工判断的 QA 训练数据，其知识可以有效地迁移到测试数据集中。</li><li>zero-shot 的 QLM 和经过 QG 指令微调的 QLM 表现出相似的竞争力，这一发现时令人惊讶的，这说明 pretrained-only 的 LLM 就具有强大的 zero-shot QLM 排名的能力。</li><li>如果 QG 任务没有出现在指令微调的数据中，那么指令微调反而会阻碍 LLM 的 QLM re-rank 能力。猜测原因在于，指令微调的模型往往更关注任务指令，而较少关注输入内容本身，但是评估 Query Likelihood 的最重要信息都在文档内容中，所以指令调优不利用 LLM 的 Query Likelihood 的估计。</li><li>BM25 插值策略的改进究竟有没有用，取决于具体的 LLM 模型。</li></ul><h3 id="_2-3-一个有效的-ranking-pipeline" tabindex="-1"><a class="header-anchor" href="#_2-3-一个有效的-ranking-pipeline"><span>2.3 一个有效的 ranking pipeline</span></a></h3><p>这篇论文工作（原文 4.3 节）还提出了一个有效的 ranking pipeline。</p><p>在第一阶段的 retriever 中，将 BM25 和 HyDE 结合作为 zero-shot first-stage hybird retriever，然后再使用 QLM 做 re-rank。</p><p>经过实验发现，这种方法可以与当前 SOTA 模型表现相当，重要的这种方法不需要任何训练。</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>这两篇论文给了我们使用 LLM 来做 QLM re-rank 的思路，展现了通用的 LLM 本身具备强大的 QLM re-rank 的能力。</p></div><!----></div><footer class="page-footer" data-v-5b0e3d8f data-v-bb1af879><!----><div class="contributors" data-v-bb1af879><span class="contributors-label" data-v-bb1af879>贡献者: </span><span class="contributors-info" data-v-bb1af879><!--[--><!--[--><span class="contributor" title="email: yubin_SkyWalker@yeah.net" data-v-bb1af879>yubinCloud</span><!----><!--]--><!--]--></span></div><!----></footer><!----><!--]--></div></div></div></div><button style="display:none;" type="button" class="back-to-top-button" aria-label="back to top" data-v-ba475dda data-v-b42999a2><span class="percent" data-v-b42999a2>0%</span><span class="show icon vpi-back-to-top" data-v-b42999a2></span><svg aria-hidden="true" data-v-b42999a2><circle cx="50%" cy="50%" style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-b42999a2></circle></svg></button><footer class="plume-footer" data-v-ba475dda data-v-46d530a6><div class="container" data-v-46d530a6><p class="message" data-v-46d530a6>Power by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://github.com/pengzhanbo/vuepress-theme-plume">vuepress-theme-plume</a></p><!----></div></footer><!--]--></div><!--]--></div><!--[--><!--]--><!--]--></div><script type="module" src="/research-notebook/assets/app-s5JIphqh.js" defer></script></body></html>