import{_ as a,r as s,o as r,c as m,a as t,b as l,d as o,w as n,e as i}from"./app-s5JIphqh.js";const c={},d={href:"https://aclanthology.org/2023.emnlp-main.327",target:"_blank",rel:"noopener noreferrer"},u=t("p",null,"⭐⭐⭐⭐",-1),h=t("p",null,"EMNLP 2023, arXiv:2305.14215",-1),g=t("h2",{id:"一、论文速读",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#一、论文速读"},[t("span",null,"一、论文速读")])],-1),_=t("p",null,"本文通过对 LLM 使用 CoT-style 的 prompting 方法来解决 Text2SQL 问题，试图回答下面两个问题：",-1),L=t("ol",null,[t("li",null,"哪种 prompting style 更好：在一个 pass 中生成所有推理步骤好，还是迭代 prompting 并解决问题好？"),t("li",null,"详细的推理步骤对于 Text2SQL 任务来说是否会产生更好的结果？")],-1),x=t("p",null,"论文在四种多步推理的 prompting 方法上做了试验，并对比了效果，下面分别介绍。",-1),b=t("h2",{id:"二、用于-text2sql-的多步推理的-prompting-方法",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#二、用于-text2sql-的多步推理的-prompting-方法"},[t("span",null,"二、用于 Text2SQL 的多步推理的 prompting 方法")])],-1),f=t("p",null,"下图是四种 prompting 的示例，输入的是相同的 DB schema 和 question，不同的 prompting 方法有期待的不同的输出：",-1),k=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717504155608.png",alt:"1717504155608",style:{zoom:"75%"}},null,-1),T=t("h3",{id:"_2-1-chain-of-thought-prompting",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#_2-1-chain-of-thought-prompting"},[t("span",null,"2.1 Chain-of-Thought Prompting")])],-1),q=t("p",null,"CoT 旨在在预测答案之前先生成一系列中间步骤从而提高 LLM 的推理能力，那如何提出这些中间步骤就是一个问题。",-1),C=t("p",null,"本文是使用 SQL query 中的每个 clause 的推理思路组成 CoT prompt 中的推理步骤。下图是一个在 Spider 上 1-shot 的 CoT 示例：",-1),Q=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717505610202.png",alt:"1717505610202",style:{zoom:"75%"}},null,-1),y=i('<ul><li>红色方框的部分是 1-shot 的 demonstration，教会 LLM 来生成思维链的推理步骤</li><li>蓝色方框的部分是我们想让 LLM 解决的 question</li></ul><h3 id="_2-2-least-to-most-prompting" tabindex="-1"><a class="header-anchor" href="#_2-2-least-to-most-prompting"><span>2.2 Least-to-Most Prompting</span></a></h3><p>CoT 是让 LLM 一次生成所有的推理步骤，而 Least-to-Most Prompting 则是在两个阶段来解决复杂问题：</p><ul><li><strong>problem reduction 阶段</strong>：提示 LLM 从原始复杂 question 中生成一系列 sub-question</li><li><strong>problem solving 阶段</strong>：每次用一个 sub-question 来 prompt LLM，并迭代地建立最终解决方案</li></ul><blockquote><p>最后一个 sub-question 就是原来的 user question。</p></blockquote><p>下图是 problem reduction 阶段的示例：</p>',6),S=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717506774090.png",alt:"1717506774090",style:{zoom:"75%"}},null,-1),M=t("p",null,"下图是 problem solving 阶段的示例：",-1),v=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717507167824.png",alt:"1717507167824",style:{zoom:"75%"}},null,-1),D=t("h3",{id:"_2-3-question-decomposition-prompting-qdecomp",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#_2-3-question-decomposition-prompting-qdecomp"},[t("span",null,"2.3 Question Decomposition Prompting（QDecomp）")])],-1),P=t("p",null,[l("这里就是本文新提出的 "),t("mark",null,"QDecomp"),l(" prompting 方法，这个方法结合 CoT 和 Least-to-Most 两种方法的特点：像 CoT 那样一次性生成中间推理步骤和最终的 SQL query，但是中间推理步骤不是之前使用 CoT 那样的 SQL 逻辑推理过程，而是遵循 Least-to-Most prompting 的 problem reduction 阶段的思路，指导 LLM 将原始复杂问题分解为推理步骤：")],-1),I=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717507972711.png",alt:"1717507972711",style:{zoom:"75%"}},null,-1),E=t("p",null,[l("在 QDecomp 基础上，本文又提出了一个变体 "),t("mark",null,"QDecomp + InterCOL"),l("，用于缓解 Text2SQL 任务中常见的 Schema Linking 的问题：他扩充了更多的 in-context exemplars，以教会 LLM 在生成每个 sub-questions 时识别出任何相应的 table/column names。")],-1),z=t("p",null,"下图是一个示例：",-1),j=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1717508828195.png",alt:"1717508828195",style:{zoom:"75%"}},null,-1),w=t("blockquote",null,[t("p",null,"这里的具体解释可以参考原论文")],-1),N=t("h2",{id:"三、实验",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#三、实验"},[t("span",null,"三、实验")])],-1),B=t("p",null,"论文使用了 Spider 和 Spider Realistic 两个数据集，ICL 的 exemplars 是采用 random selection 得到的。LLM 使用 Codex。Prompt Format 使用了 API Docs 的格式。",-1),O=t("p",null,"具体实验上，测试了不同的 prompting 方法，顺带还有 standard prompting 方法作为 baseline。",-1),V=t("blockquote",null,[t("p",null,"standard prompting 方法指的是使用几个 question-SQL pairs 作为 ICL 的 exemplars 来直接 prompt LLM 得到答案，整个过程不涉及中间推理过程。")],-1),A=t("p",null,"实验数据如下：",-1),R=t("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20240604215320.png",alt:"20240604215320",style:{zoom:"75%"}},null,-1),F=i('<p>得出如下结论：</p><ul><li>QDecomp 和 QDecomp + InterCOL 方法的表现均超过了 CoT 和 Least-to-Most</li><li>对于 Text2SQL 来说，迭代式地解决一系列 sub-questions 可能不是必需的，况且这种方法的成本还很高。</li><li>CoT prompting 甚至比 standard prompting 效果更差</li></ul><h3 id="_3-1-误差分析-cot-效果甚至不如-standard-prompting" tabindex="-1"><a class="header-anchor" href="#_3-1-误差分析-cot-效果甚至不如-standard-prompting"><span>3.1 误差分析：CoT 效果甚至不如 standard prompting</span></a></h3><p>通过对 error cases 的分析，发现，<strong>由于 CoT 会生成详细的推理步骤，而这中间任何一步出错都会导致错误传播，从而导致最后的答案出现错误</strong>。</p><p>而 QDecomp 方法不指示 LLM 生成详细的推理步骤或者中间 SQL query，这样就减少了推理步骤中错误累积的可能性。</p><h3 id="_3-2-prompt-的设计" tabindex="-1"><a class="header-anchor" href="#_3-2-prompt-的设计"><span>3.2 Prompt 的设计</span></a></h3><ul><li><strong>ICL Examples 的选择</strong>：发现 QDecomp + InterCOL 方法具备不错的鲁棒性</li><li><strong>ICL Examples 的数量</strong>：本文发现当样本数量超过 8 时，带来的增益较小，因此本文使用了 8 个上下文示例</li><li><strong>ICL Examples 的格式</strong>：测试了两种 prompt 格式：<em>API Docs</em> 和 <em>Create Table + Select 3</em></li></ul><h2 id="四、总结" tabindex="-1"><a class="header-anchor" href="#四、总结"><span>四、总结</span></a></h2><p>本文基于 Codex 的 LLM 来探索了 CoT-style 的 prompting 效果，增强了 LLM 对 Text2SQL 解析的推理能力。</p><p>论文发现了 CoT 在 Text2SQL 任务中会出现错误传播问题，本文提出的 QDecomp 方法是缓解 LLM 多步骤推理中错误传播问题的尝试之一，之后值得对这个问题进行更深一步的探讨。</p>',10);function J(W,X){const p=s("ExternalLinkIcon"),e=s("center");return r(),m("div",null,[t("blockquote",null,[t("p",null,[l("论文："),t("a",d,[l("Exploring Chain of Thought Style Prompting for Text-to-SQL"),o(p)])]),u,h]),g,_,L,x,b,f,o(e,null,{default:n(()=>[k]),_:1}),T,q,C,o(e,null,{default:n(()=>[Q]),_:1}),y,o(e,null,{default:n(()=>[S]),_:1}),M,o(e,null,{default:n(()=>[v]),_:1}),D,P,o(e,null,{default:n(()=>[I]),_:1}),E,z,o(e,null,{default:n(()=>[j]),_:1}),w,N,B,O,V,A,o(e,null,{default:n(()=>[R]),_:1}),F])}const G=a(c,[["render",J],["__file","index.html.vue"]]),H=JSON.parse(`{"path":"/arxiv/2305.14215/","title":"🌙 QDecomp：探索 CoT-style 的 prompt 来解决 Text2SQL","lang":"zh-CN","frontmatter":{"title":"🌙 QDecomp：探索 CoT-style 的 prompt 来解决 Text2SQL","author":"Bin Yu","createTime":"2024/06/04 16:59:00","permalink":"/arxiv/2305.14215/","head":[["script",{"id":"check-dark-mode"},";(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;if (um === 'dark' || (um !== 'light' && sm)) {document.documentElement.classList.add('dark');}})();"],["script",{"id":"check-mac-os"},"document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))"]]},"headers":[{"level":2,"title":"一、论文速读","slug":"一、论文速读","link":"#一、论文速读","children":[]},{"level":2,"title":"二、用于 Text2SQL 的多步推理的 prompting 方法","slug":"二、用于-text2sql-的多步推理的-prompting-方法","link":"#二、用于-text2sql-的多步推理的-prompting-方法","children":[{"level":3,"title":"2.1 Chain-of-Thought Prompting","slug":"_2-1-chain-of-thought-prompting","link":"#_2-1-chain-of-thought-prompting","children":[]},{"level":3,"title":"2.2 Least-to-Most Prompting","slug":"_2-2-least-to-most-prompting","link":"#_2-2-least-to-most-prompting","children":[]},{"level":3,"title":"2.3 Question Decomposition Prompting（QDecomp）","slug":"_2-3-question-decomposition-prompting-qdecomp","link":"#_2-3-question-decomposition-prompting-qdecomp","children":[]}]},{"level":2,"title":"三、实验","slug":"三、实验","link":"#三、实验","children":[{"level":3,"title":"3.1 误差分析：CoT 效果甚至不如 standard prompting","slug":"_3-1-误差分析-cot-效果甚至不如-standard-prompting","link":"#_3-1-误差分析-cot-效果甚至不如-standard-prompting","children":[]},{"level":3,"title":"3.2 Prompt 的设计","slug":"_3-2-prompt-的设计","link":"#_3-2-prompt-的设计","children":[]}]},{"level":2,"title":"四、总结","slug":"四、总结","link":"#四、总结","children":[]}],"readingTime":{"minutes":4.16,"words":1247},"git":{"updatedTime":1717830098000,"contributors":[{"name":"yubinCloud","email":"yubin_SkyWalker@yeah.net","commits":2}]},"filePathRelative":"notes/Text2SQL/2305.QDecomp.md","categoryList":[{"type":10000,"name":"notes"},{"type":10004,"name":"Text2SQL"}]}`);export{G as comp,H as data};
