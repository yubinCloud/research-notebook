import{_ as n,r,o as s,c as i,a as e,b as t,d as a,e as l}from"./app-s5JIphqh.js";const c={},d={href:"https://openreview.net/forum?id=ZS4m74kZpH",target:"_blank",rel:"noopener noreferrer"},p=e("p",null,"⭐⭐⭐",-1),u=e("p",null,"ICLR 2024, arXiv:2310.01558",-1),h={href:"https://github.com/oriyor/ret-robust",target:"_blank",rel:"noopener noreferrer"},m=l('<h2 id="论文速读" tabindex="-1"><a class="header-anchor" href="#论文速读"><span>论文速读</span></a></h2><p>这篇论文引入 NLI（Natural Language Inference）模型来判定 retrieved doc 是否需要用于辅助 LLM 回答。</p><p>NLI 模型用于判定一个 hypothesis 与 premise 的关系如下三者之一：&quot;蕴含（entailed）&quot;、&quot;中立（neutral）&quot;、&quot;矛盾（contradicted）&quot;。<strong>具体到 RAG 中，question + LLM answer 作为 premise，retrieved doc 作为 hypothesis，由 NLI 模型判定两者是否是 entailed</strong>：</p><ul><li>是的话，就辅助 LLM 再次生成 answer 作为最终答案</li><li>不是的话，就使用标准的 LLM，防止无关上下文来分散 LLM 的注意力</li></ul><blockquote><p>该论文的工作，NLI 模型使用的是 BART-large</p></blockquote><p><strong>这其实这篇论文的假设是有问题的，以底座模型的答案作为基准来衡量检索信息是否是噪声，那其实把 RAG 通过检索召回额外信息增加 LLM 本身缺乏的知识的这部分的能力也损失了。这种假设在底座本身就能回答的问题上额外增加了相关召回信息，可能会让底座的答案更加详细精准。但是底座本身不能回答或者回答错误的部分，那基于底座的答案去做噪声判断会让让模型错上加错</strong>。</p><p>此外，该论文工作还尝试训练一个健壮的用于 RAG 的 LLM。因为作者认为，原生的 LLM 由于其没有在 retrieved passages 上做训练，所以它对噪音上下文很脆弱是可以预料的。为此，作者特意收集一批带有噪音文档的数据来对 LLM 做 SFT，数据的收集其实就是将检索到的 top-1 和排名较低的文档共同作为 retrieved context。<strong>这种做法其实就是在训练样本中强行引入噪声，让模型学习识别噪声的能力，当引入噪声信息时能够基于底座本身具有的知识正确作答</strong>。</p><h2 id="实验结果" tabindex="-1"><a class="header-anchor" href="#实验结果"><span>实验结果</span></a></h2><p>通过实验发现，论文提出的采用 NLI 来识别无关文档的方法，由于其假设有点问题，导致其底座模型在本身信息缺失的情况西，做降低 RAG 的性能，因为它把与底座答案不一致的正确信息都过滤了。</p><p>另外，使用含有噪音检索上下文的数据来对底座模型做 SFT 之后，即便加入不相关的召回信息都可以让 RAG 模型变好，这说明引入噪声做 SFT 的方式可以有助于帮助 RAG 模型在一定程度上去除噪声带来的影响。</p><h2 id="反思" tabindex="-1"><a class="header-anchor" href="#反思"><span>反思</span></a></h2><ul><li><strong>在实际业务落地上可以借鉴引入随机噪声的思想，在 sft 阶段不仅只加入最相关的召回结果，同时以一定的比例加入随机召回信息作为噪声</strong>，可以提升模型识别噪声的能力，在线上推理阶段，如果 top 的召回信息是不相关的错误信息，模型有一定的识别能力。</li><li>我们其实可以在 RAG 的过程中增加判断召回文档是否相关，以及结合相关文档给出正确答案这样的 cot 任务，这样输出的内容不会过长，不会带来额外的线上推理耗时，同时也能一定程度上缓解 RAG 检索信息存在噪声的问题。</li></ul>',12);function L(g,_){const o=r("ExternalLinkIcon");return s(),i("div",null,[e("blockquote",null,[e("p",null,[t("论文："),e("a",d,[t("Making Retrieval-Augmented Language Models Robust to Irrelevant Context"),a(o)])]),p,u,e("p",null,[t("Code: "),e("a",h,[t("github.com/oriyor/ret-robust"),a(o)])])]),m])}const f=n(c,[["render",L],["__file","index.html.vue"]]),v=JSON.parse(`{"path":"/arxiv/2310.01558/","title":"🐋 引入 NLI 模型来为 RAG 去噪","lang":"zh-CN","frontmatter":{"title":"🐋 引入 NLI 模型来为 RAG 去噪","permalink":"/arxiv/2310.01558/","author":"Bin Yu","createTime":"2024/05/15 17:11:00","head":[["script",{"id":"check-dark-mode"},";(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;if (um === 'dark' || (um !== 'light' && sm)) {document.documentElement.classList.add('dark');}})();"],["script",{"id":"check-mac-os"},"document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))"]]},"headers":[{"level":2,"title":"论文速读","slug":"论文速读","link":"#论文速读","children":[]},{"level":2,"title":"实验结果","slug":"实验结果","link":"#实验结果","children":[]},{"level":2,"title":"反思","slug":"反思","link":"#反思","children":[]}],"readingTime":{"minutes":2.98,"words":893},"git":{"updatedTime":1716026122000,"contributors":[{"name":"yubinCloud","email":"yubin_SkyWalker@yeah.net","commits":2}]},"filePathRelative":"notes/RAG/2310.引入 NLI 模型来为 RAG 去噪.md","categoryList":[{"type":10000,"name":"notes"},{"type":10003,"name":"RAG"}]}`);export{f as comp,v as data};
