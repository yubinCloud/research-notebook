import{_ as c,r as l,o as r,c as d,a as e,b as t,d as o,w as s}from"./app-s5JIphqh.js";const u={},m={href:"https://aclanthology.org/2021.eacl-main.74",target:"_blank",rel:"noopener noreferrer"},h=e("p",null,"⭐⭐⭐⭐",-1),p=e("p",null,"EACL 2021, Facebook AI Research",-1),_=e("h2",{id:"论文速读",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#论文速读"},[e("span",null,"论文速读")])],-1),g=e("p",null,[t("在 RAG 中，"),e("strong",null,"如何将检索出的 passages 做聚合并输入到生成模型是一个问题"),t("，本文提出了一个简单有效的方案：FiD。")],-1),f=e("p",null,[t("下图是一个简单的 open-domain QA 的使用方式，它直接将 question 和检索到的所有 passages 拼接起来，以 "),e("code",null,"<question, retrieved passages>"),t(" 的形式扔给 seq2seq 模型来生成 answer：")],-1),v=e("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20240512210853.png",alt:"20240512210853",style:{zoom:"75%"}},null,-1),k=e("p",null,"这种处理方式中，随着 retrieved passages 的数量增多，由于 Self-Attention 的运算机制，计算复杂度会呈现二次增长。",-1),b=e("mark",null,"FiD",-1),y=e("strong",null,"Fusion-in-Decoder",-1),x=e("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20240512211400.png",alt:"20240512211400",style:{zoom:"75%"}},null,-1),q=e("p",null,"尽管方法简单，但效果却出奇的好，在当时 TriviaQA 和 NaturalQuestions 的 benchmark 上达到了 SOTA 水平：",-1),w=e("blockquote",null,[e("p",null,"While conceptually simple, this method sets new state-of-the-art results on the TriviaQA and NaturalQuestions benchmarks.")],-1),A=e("p",null,[t("同时，"),e("strong",null,"作者认为，与检索模型相比，生成模型非常善于将多个 passages 的信息进行合成，所以本工作的 retrieved passages 的合成工作是交给了生成模型的 Decoder 来做的"),t("：")],-1),D=e("blockquote",null,[e("p",null,"We believe that this is evidence that generative mod els are good at combining evidence from multiple passages, compared to extractive ones.")],-1),L=e("h2",{id:"实验结果",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#实验结果"},[e("span",null,"实验结果")])],-1),F=e("p",null,"与其他 baselines 的对比：",-1),M=e("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20240512211933.png",alt:"20240512211933",style:{zoom:"75%"}},null,-1),N=e("p",null,"作者还测试了一下 FiD 在 valid set 上的 performance 与 retrieved passages 数量的函数关系：",-1),R=e("img",{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20240512212100.png",alt:"20240512212100",style:{zoom:"75%"}},null,-1),T=e("p",null,"可以看到，随着输入的 passages 越多，模型的性能就越好，但同时由于拼接后给 decoder 的输入变长，肯定会伴随着计算机内存的增长。",-1),E=e("h2",{id:"总结",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#总结"},[e("span",null,"总结")])],-1),Q=e("p",null,"FiD 给出了一种将 retrieved passages 如何聚合输入给生成模型的思路，这种方法相比于传统的全部拼接再给 LLM 的优势在于：",-1),z=e("ul",null,[e("li",null,"encoder 独立处理每个 passage，因此只需要在一个 passage 上执行 self-attention，这意味着模型的计算时间随着段落数量呈线性增长，而非二次增长。"),e("li",null,"由 decoder 来联合聚合多个 retrieved passages，可以更好的从中找到相关支持信息。")],-1),C=e("p",null,"论文最后指出，如何将 FiD 更好集成到 RAG 模型仍然值得探索。",-1);function G(P,S){const a=l("ExternalLinkIcon"),n=l("center"),i=l("font");return r(),d("div",null,[e("blockquote",null,[e("p",null,[t("论文： "),e("a",m,[t("Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"),o(a)])]),h,p]),_,g,f,o(n,null,{default:s(()=>[v]),_:1}),k,e("p",null,[t("本论文提出了一个简单直接的方法 —— "),b,t("（"),y,t("）—— "),o(i,{color:"blue"},{default:s(()=>[t("将检索回来的每一个 passage 都独立与 question 用一些特殊符号作为间隔拼接起来并输给 encoder 做编码，然后 concat 在一起输入给 decoder 生成 final answer")]),_:1}),t("，所以称之为 Fusion-in-Decoder：")]),o(n,null,{default:s(()=>[x]),_:1}),q,w,A,D,L,F,o(n,null,{default:s(()=>[M]),_:1}),N,o(n,null,{default:s(()=>[R]),_:1}),T,E,Q,z,C])}const B=c(u,[["render",G],["__file","index.html.vue"]]),I=JSON.parse(`{"path":"/arxiv/2007.01282/","title":"🐋 FiD：一种将 retrieved docs 合并输入给 LM 的方法","lang":"zh-CN","frontmatter":{"title":"🐋 FiD：一种将 retrieved docs 合并输入给 LM 的方法","permalink":"/arxiv/2007.01282/","author":"Bin Yu","createTime":"2024/05/12 20:57:00","head":[["script",{"id":"check-dark-mode"},";(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;if (um === 'dark' || (um !== 'light' && sm)) {document.documentElement.classList.add('dark');}})();"],["script",{"id":"check-mac-os"},"document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))"]]},"headers":[{"level":2,"title":"论文速读","slug":"论文速读","link":"#论文速读","children":[]},{"level":2,"title":"实验结果","slug":"实验结果","link":"#实验结果","children":[]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]}],"readingTime":{"minutes":2.26,"words":678},"git":{"updatedTime":1716026122000,"contributors":[{"name":"yubinCloud","email":"yubin_SkyWalker@yeah.net","commits":2}]},"filePathRelative":"notes/RAG/2007.FiD：一种将 retrieved docs 合并输入给 LM 的方法.md","categoryList":[{"type":10000,"name":"notes"},{"type":10003,"name":"RAG"}]}`);export{B as comp,I as data};
